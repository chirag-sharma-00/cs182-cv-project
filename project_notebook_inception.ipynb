{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pathlib\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv(\"../data/tiny-imagenet-200/tiny-imagenet-200/words.txt\", names = ['Id', 'labels'], sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3bf98b5cfeb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimages_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg_class\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varun jadia\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2895\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varun jadia\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2948\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2949\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2950\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2951\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#takes a while to run\n",
    "images_expanded = pd.DataFrame(columns = ['Id', 'label'])\n",
    "for img in images['Id']: \n",
    "    classes = images[images['Id'] == img]['labels']\n",
    "    \n",
    "    for img_class in classes: \n",
    "        images_expanded = images_expanded.append({'Id': img, 'label' : img_class}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_expanded.to_csv('words_expande.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('../data/tiny-imagenet-200/tiny-imagenet-200/')\n",
    "image_count = len(list(data_dir.glob('**/*.JPEG')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in (data_dir / 'train').glob('*')])\n",
    "sum([cls in images['Id'].unique() for cls in CLASS_NAMES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Inception v3 out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = data_dir\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"inception_v3\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 200\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Number of epochs to train for\n",
    "num_epochs = 3\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "# when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Varun Jadia/.cache\\torch\\hub\\pytorch_vision_v0.9.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change last layers in model to match tiny imagenet\n",
    "model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "model.fc = nn.Linear(2048, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception expects input size 3*299*299\n",
    "input_size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on one image\n",
    "input_image_one = Image.open(\"../data/tiny-imagenet-200/train/n01443537/images/n01443537_0.JPEG\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#converts image to 3*299*299\n",
    "input_tensor_one = preprocess(input_image_one)\n",
    "\n",
    "#convert to batches\n",
    "input_batch = torch.cat((input_tensor_one.unsqueeze(0), input_tensor_one.unsqueeze(0)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5844, 0.5588, 0.3677, 0.5314, 0.5706, 0.6019, 0.4203, 0.4587, 0.4384,\n",
      "         0.4523, 0.5917, 0.3619, 0.5725, 0.5263, 0.5770, 0.4273, 0.5186, 0.4732,\n",
      "         0.4843, 0.4914, 0.4898, 0.5532, 0.3608, 0.4117, 0.5177, 0.4508, 0.4183,\n",
      "         0.4943, 0.3829, 0.5474, 0.4819, 0.4926, 0.3652, 0.5660, 0.5301, 0.4787,\n",
      "         0.5190, 0.5015, 0.4638, 0.4591, 0.5849, 0.5683, 0.5857, 0.4282, 0.4621,\n",
      "         0.4564, 0.4820, 0.4796, 0.6487, 0.4802, 0.4647, 0.4301, 0.5059, 0.5488,\n",
      "         0.4507, 0.4437, 0.5217, 0.5219, 0.5793, 0.4818, 0.4189, 0.5636, 0.5038,\n",
      "         0.4650, 0.5408, 0.5289, 0.4281, 0.5002, 0.4047, 0.4398, 0.4407, 0.4156,\n",
      "         0.5662, 0.3598, 0.5238, 0.4666, 0.5090, 0.5307, 0.6265, 0.4710, 0.5150,\n",
      "         0.4765, 0.4898, 0.5103, 0.4711, 0.5628, 0.5575, 0.4731, 0.4463, 0.4282,\n",
      "         0.4772, 0.5152, 0.4514, 0.3888, 0.4413, 0.5423, 0.3222, 0.4871, 0.4790,\n",
      "         0.5980, 0.5976, 0.5118, 0.5747, 0.6341, 0.5709, 0.3892, 0.4369, 0.4421,\n",
      "         0.5213, 0.5090, 0.6242, 0.4180, 0.3945, 0.4812, 0.3436, 0.3842, 0.4814,\n",
      "         0.5393, 0.5425, 0.5647, 0.4958, 0.4911, 0.5228, 0.4422, 0.4616, 0.4947,\n",
      "         0.5018, 0.5346, 0.5036, 0.5664, 0.5738, 0.5435, 0.4918, 0.5150, 0.5483,\n",
      "         0.5410, 0.5535, 0.4405, 0.5338, 0.5302, 0.4734, 0.5221, 0.3667, 0.4517,\n",
      "         0.5259, 0.4781, 0.4061, 0.4777, 0.4295, 0.4492, 0.4797, 0.4575, 0.4318,\n",
      "         0.5565, 0.5446, 0.4901, 0.5642, 0.5287, 0.5146, 0.3734, 0.5192, 0.3645,\n",
      "         0.5425, 0.4767, 0.3675, 0.5026, 0.5658, 0.4136, 0.4440, 0.5438, 0.5650,\n",
      "         0.4941, 0.4934, 0.4384, 0.4429, 0.5729, 0.4555, 0.5169, 0.4107, 0.5615,\n",
      "         0.5264, 0.4046, 0.6243, 0.5272, 0.5200, 0.5202, 0.4667, 0.5179, 0.6073,\n",
      "         0.5679, 0.4803, 0.4520, 0.5419, 0.4098, 0.4231, 0.4069, 0.5049, 0.5019,\n",
      "         0.4856, 0.5361],\n",
      "        [0.4156, 0.4412, 0.6323, 0.4686, 0.4294, 0.3981, 0.5797, 0.5413, 0.5616,\n",
      "         0.5477, 0.4083, 0.6381, 0.4275, 0.4737, 0.4230, 0.5727, 0.4814, 0.5268,\n",
      "         0.5157, 0.5086, 0.5102, 0.4468, 0.6392, 0.5883, 0.4823, 0.5492, 0.5817,\n",
      "         0.5057, 0.6171, 0.4526, 0.5181, 0.5074, 0.6348, 0.4340, 0.4699, 0.5213,\n",
      "         0.4810, 0.4985, 0.5362, 0.5409, 0.4151, 0.4317, 0.4143, 0.5718, 0.5379,\n",
      "         0.5436, 0.5180, 0.5204, 0.3513, 0.5198, 0.5353, 0.5699, 0.4941, 0.4512,\n",
      "         0.5493, 0.5563, 0.4783, 0.4781, 0.4207, 0.5182, 0.5811, 0.4364, 0.4962,\n",
      "         0.5350, 0.4592, 0.4711, 0.5719, 0.4998, 0.5953, 0.5602, 0.5593, 0.5844,\n",
      "         0.4338, 0.6402, 0.4762, 0.5334, 0.4910, 0.4693, 0.3735, 0.5290, 0.4850,\n",
      "         0.5235, 0.5102, 0.4897, 0.5289, 0.4372, 0.4425, 0.5269, 0.5537, 0.5718,\n",
      "         0.5228, 0.4848, 0.5486, 0.6112, 0.5587, 0.4577, 0.6778, 0.5129, 0.5210,\n",
      "         0.4020, 0.4024, 0.4882, 0.4253, 0.3659, 0.4291, 0.6108, 0.5631, 0.5579,\n",
      "         0.4787, 0.4910, 0.3758, 0.5820, 0.6055, 0.5188, 0.6564, 0.6158, 0.5186,\n",
      "         0.4607, 0.4575, 0.4353, 0.5042, 0.5089, 0.4772, 0.5578, 0.5384, 0.5053,\n",
      "         0.4982, 0.4654, 0.4964, 0.4336, 0.4262, 0.4565, 0.5082, 0.4850, 0.4517,\n",
      "         0.4590, 0.4465, 0.5595, 0.4662, 0.4698, 0.5266, 0.4779, 0.6333, 0.5483,\n",
      "         0.4741, 0.5219, 0.5939, 0.5223, 0.5705, 0.5508, 0.5203, 0.5425, 0.5682,\n",
      "         0.4435, 0.4554, 0.5099, 0.4358, 0.4713, 0.4854, 0.6266, 0.4808, 0.6355,\n",
      "         0.4575, 0.5233, 0.6325, 0.4974, 0.4342, 0.5864, 0.5560, 0.4562, 0.4350,\n",
      "         0.5059, 0.5066, 0.5616, 0.5571, 0.4271, 0.5445, 0.4831, 0.5893, 0.4385,\n",
      "         0.4736, 0.5954, 0.3757, 0.4728, 0.4800, 0.4798, 0.5333, 0.4821, 0.3927,\n",
      "         0.4321, 0.5197, 0.5480, 0.4581, 0.5902, 0.5769, 0.5931, 0.4951, 0.4981,\n",
      "         0.5144, 0.4639]])\n"
     ]
    }
   ],
   "source": [
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6487, 0.6341, 0.6265, 0.6243, 0.6242]),\n",
       "indices=tensor([ 48, 103,  78, 182, 110]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(probabilities[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../data/tiny-imagenet-200/wnids.txt\", names = ['class_labels'], sep = '\\t')\n",
    "labels['predictions'] = probabilities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_labels</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>n02233338</td>\n",
       "      <td>0.648720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>n03126707</td>\n",
       "      <td>0.634147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>n02099601</td>\n",
       "      <td>0.626471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>n02085620</td>\n",
       "      <td>0.624325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>n03014705</td>\n",
       "      <td>0.624234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n02106662</td>\n",
       "      <td>0.361941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>n01443537</td>\n",
       "      <td>0.360817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>n02423022</td>\n",
       "      <td>0.359763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>n03670208</td>\n",
       "      <td>0.343643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>n03992509</td>\n",
       "      <td>0.322247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_labels  predictions\n",
       "48     n02233338     0.648720\n",
       "103    n03126707     0.634147\n",
       "78     n02099601     0.626471\n",
       "182    n02085620     0.624325\n",
       "110    n03014705     0.624234\n",
       "..           ...          ...\n",
       "11     n02106662     0.361941\n",
       "22     n01443537     0.360817\n",
       "73     n02423022     0.359763\n",
       "114    n03670208     0.343643\n",
       "96     n03992509     0.322247\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sort_values(by = ['predictions'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating feature extraction to match our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=1, is_inception=True):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training (no val for now)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting=True):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloaders, model): \n",
    "    \"\"\"\n",
    "    Run a forward pass (without caching data) for given model and return accuracy\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    model.eval()\n",
    "    \n",
    "    for phase in tqdm.tqdm(['train', 'val']): \n",
    "        counter = 0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in tqdm.tqdm(dataloaders[phase]): \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            counter += 1\n",
    "            \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if counter == 100:\n",
    "                break\n",
    "            \n",
    "        phase_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "        print(phase_acc)\n",
    "        accuracies.append(phase_acc)\n",
    "\n",
    "    return accuracies\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##inception model to finetune\n",
    "model_ft = models.inception_v3(pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, feature_extract)\n",
    "# Handle the auxilary net, requires_grads automatically set to true \n",
    "num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "# Handle the primary net, requires_grad automatically set to true \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "input_size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##out of the box model\n",
    "scratch_model = models.inception_v3(pretrained=True)\n",
    "scratch_model.fc = nn.Linear(scratch_model.fc.in_features, 200)\n",
    "scratch_model.AuxLogits.fc = nn.Linear(scratch_model.AuxLogits.fc.in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check accuracy of out of the box model on all labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                        | 0/12500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                             | 1/12500 [00:08<28:33:24,  8.22s/it]\u001b[A\n",
      "  0%|                                                                             | 2/12500 [00:09<21:32:28,  6.20s/it]\u001b[A\n",
      "  0%|                                                                             | 3/12500 [00:11<16:33:35,  4.77s/it]\u001b[A\n",
      "  0%|                                                                             | 4/12500 [00:12<12:54:20,  3.72s/it]\u001b[A\n",
      "  0%|                                                                             | 5/12500 [00:13<10:12:29,  2.94s/it]\u001b[A\n",
      "  0%|                                                                              | 6/12500 [00:14<8:16:57,  2.39s/it]\u001b[A\n",
      "  0%|                                                                              | 7/12500 [00:16<7:26:37,  2.14s/it]\u001b[A\n",
      "  0%|                                                                              | 8/12500 [00:18<7:15:20,  2.09s/it]\u001b[A\n",
      "  0%|                                                                              | 9/12500 [00:19<6:26:04,  1.85s/it]\u001b[A\n",
      "  0%|                                                                             | 10/12500 [00:20<5:48:26,  1.67s/it]\u001b[A\n",
      "  0%|                                                                             | 11/12500 [00:21<5:15:39,  1.52s/it]\u001b[A\n",
      "  0%|                                                                             | 12/12500 [00:23<5:14:24,  1.51s/it]\u001b[A\n",
      "  0%|                                                                             | 13/12500 [00:25<5:45:53,  1.66s/it]\u001b[A\n",
      "  0%|                                                                             | 14/12500 [00:26<5:19:55,  1.54s/it]\u001b[A\n",
      "  0%|                                                                             | 15/12500 [00:27<4:56:30,  1.42s/it]\u001b[A\n",
      "  0%|                                                                             | 16/12500 [00:29<4:44:17,  1.37s/it]\u001b[A\n",
      "  0%|                                                                             | 17/12500 [00:30<4:32:14,  1.31s/it]\u001b[A\n",
      "  0%|                                                                             | 18/12500 [00:31<4:39:00,  1.34s/it]\u001b[A\n",
      "  0%|                                                                             | 19/12500 [00:33<5:23:22,  1.55s/it]\u001b[A\n",
      "  0%|                                                                             | 20/12500 [00:34<5:07:48,  1.48s/it]\u001b[A\n",
      "  0%|▏                                                                            | 21/12500 [00:37<5:42:44,  1.65s/it]\u001b[A\n",
      "  0%|▏                                                                            | 22/12500 [00:38<5:27:04,  1.57s/it]\u001b[A\n",
      "  0%|▏                                                                            | 23/12500 [00:40<5:44:16,  1.66s/it]\u001b[A\n",
      "  0%|▏                                                                            | 24/12500 [00:42<5:52:33,  1.70s/it]\u001b[A\n",
      "  0%|▏                                                                            | 25/12500 [00:43<5:35:06,  1.61s/it]\u001b[A\n",
      "  0%|▏                                                                            | 26/12500 [00:44<5:15:50,  1.52s/it]\u001b[A\n",
      "  0%|▏                                                                            | 27/12500 [00:46<5:46:46,  1.67s/it]\u001b[A\n",
      "  0%|▏                                                                            | 28/12500 [00:48<5:42:09,  1.65s/it]\u001b[A\n",
      "  0%|▏                                                                            | 29/12500 [00:49<5:24:46,  1.56s/it]\u001b[A\n",
      "  0%|▏                                                                            | 30/12500 [00:51<5:09:43,  1.49s/it]\u001b[A\n",
      "  0%|▏                                                                            | 31/12500 [00:52<4:55:10,  1.42s/it]\u001b[A\n",
      "  0%|▏                                                                            | 32/12500 [00:53<4:48:54,  1.39s/it]\u001b[A\n",
      "  0%|▏                                                                            | 33/12500 [00:55<4:56:08,  1.43s/it]\u001b[A\n",
      "  0%|▏                                                                            | 34/12500 [00:56<4:59:58,  1.44s/it]\u001b[A\n",
      "  0%|▏                                                                            | 35/12500 [00:58<4:58:17,  1.44s/it]\u001b[A\n",
      "  0%|▏                                                                            | 36/12500 [00:59<5:02:39,  1.46s/it]\u001b[A\n",
      "  0%|▏                                                                            | 37/12500 [01:00<4:56:32,  1.43s/it]\u001b[A\n",
      "  0%|▏                                                                            | 38/12500 [01:02<4:53:54,  1.42s/it]\u001b[A\n",
      "  0%|▏                                                                            | 39/12500 [01:03<4:51:11,  1.40s/it]\u001b[A\n",
      "  0%|▏                                                                            | 40/12500 [01:04<4:44:57,  1.37s/it]\u001b[A\n",
      "  0%|▎                                                                            | 41/12500 [01:06<4:38:33,  1.34s/it]\u001b[A\n",
      "  0%|▎                                                                            | 42/12500 [01:07<4:34:23,  1.32s/it]\u001b[A\n",
      "  0%|▎                                                                            | 43/12500 [01:08<4:25:35,  1.28s/it]\u001b[A\n",
      "  0%|▎                                                                            | 44/12500 [01:09<4:24:07,  1.27s/it]\u001b[A\n",
      "  0%|▎                                                                            | 45/12500 [01:11<4:13:43,  1.22s/it]\u001b[A\n",
      "  0%|▎                                                                            | 46/12500 [01:12<4:01:27,  1.16s/it]\u001b[A\n",
      "  0%|▎                                                                            | 47/12500 [01:13<3:57:46,  1.15s/it]\u001b[A\n",
      "  0%|▎                                                                            | 48/12500 [01:14<3:55:28,  1.13s/it]\u001b[A\n",
      "  0%|▎                                                                            | 49/12500 [01:15<3:55:43,  1.14s/it]\u001b[A\n",
      "  0%|▎                                                                            | 50/12500 [01:16<3:52:56,  1.12s/it]\u001b[A\n",
      "  0%|▎                                                                            | 51/12500 [01:17<3:47:40,  1.10s/it]\u001b[A\n",
      "  0%|▎                                                                            | 52/12500 [01:18<3:42:44,  1.07s/it]\u001b[A\n",
      "  0%|▎                                                                            | 53/12500 [01:19<3:42:08,  1.07s/it]\u001b[A\n",
      "  0%|▎                                                                            | 54/12500 [01:20<3:41:27,  1.07s/it]\u001b[A\n",
      "  0%|▎                                                                            | 55/12500 [01:21<3:40:27,  1.06s/it]\u001b[A\n",
      "  0%|▎                                                                            | 56/12500 [01:22<3:39:12,  1.06s/it]\u001b[A\n",
      "  0%|▎                                                                            | 57/12500 [01:23<3:39:34,  1.06s/it]\u001b[A\n",
      "  0%|▎                                                                            | 58/12500 [01:24<3:38:25,  1.05s/it]\u001b[A\n",
      "  0%|▎                                                                            | 59/12500 [01:25<3:38:39,  1.05s/it]\u001b[A\n",
      "  0%|▎                                                                            | 60/12500 [01:27<3:43:33,  1.08s/it]\u001b[A\n",
      "  0%|▍                                                                            | 61/12500 [01:28<3:48:25,  1.10s/it]\u001b[A\n",
      "  0%|▍                                                                            | 62/12500 [01:29<3:54:19,  1.13s/it]\u001b[A\n",
      "  1%|▍                                                                            | 63/12500 [01:30<3:48:30,  1.10s/it]\u001b[A\n",
      "  1%|▍                                                                            | 64/12500 [01:31<3:51:06,  1.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                            | 65/12500 [01:32<3:58:35,  1.15s/it]\u001b[A\n",
      "  1%|▍                                                                            | 66/12500 [01:33<3:53:20,  1.13s/it]\u001b[A\n",
      "  1%|▍                                                                            | 67/12500 [01:35<3:52:37,  1.12s/it]\u001b[A\n",
      "  1%|▍                                                                            | 68/12500 [01:36<3:48:45,  1.10s/it]\u001b[A\n",
      "  1%|▍                                                                            | 69/12500 [01:37<4:07:28,  1.19s/it]\u001b[A\n",
      "  1%|▍                                                                            | 70/12500 [01:38<4:11:44,  1.22s/it]\u001b[A\n",
      "  1%|▍                                                                            | 71/12500 [01:39<4:01:16,  1.16s/it]\u001b[A\n",
      "  1%|▍                                                                            | 72/12500 [01:41<4:11:40,  1.22s/it]\u001b[A\n",
      "  1%|▍                                                                            | 73/12500 [01:42<4:03:16,  1.17s/it]\u001b[A\n",
      "  1%|▍                                                                            | 74/12500 [01:43<3:59:22,  1.16s/it]\u001b[A\n",
      "  1%|▍                                                                            | 75/12500 [01:44<3:53:51,  1.13s/it]\u001b[A\n",
      "  1%|▍                                                                            | 76/12500 [01:45<3:53:30,  1.13s/it]\u001b[A\n",
      "  1%|▍                                                                            | 77/12500 [01:46<3:56:19,  1.14s/it]\u001b[A\n",
      "  1%|▍                                                                            | 78/12500 [01:48<4:11:44,  1.22s/it]\u001b[A\n",
      "  1%|▍                                                                            | 79/12500 [01:49<4:07:49,  1.20s/it]\u001b[A\n",
      "  1%|▍                                                                            | 80/12500 [01:50<4:05:30,  1.19s/it]\u001b[A\n",
      "  1%|▍                                                                            | 81/12500 [01:51<4:07:37,  1.20s/it]\u001b[A\n",
      "  1%|▌                                                                            | 82/12500 [01:52<4:04:19,  1.18s/it]\u001b[A\n",
      "  1%|▌                                                                            | 83/12500 [01:53<3:57:11,  1.15s/it]\u001b[A\n",
      "  1%|▌                                                                            | 84/12500 [01:55<4:09:16,  1.20s/it]\u001b[A\n",
      "  1%|▌                                                                            | 85/12500 [01:56<4:02:21,  1.17s/it]\u001b[A\n",
      "  1%|▌                                                                            | 86/12500 [01:57<4:03:15,  1.18s/it]\u001b[A\n",
      "  1%|▌                                                                            | 87/12500 [01:58<4:07:04,  1.19s/it]\u001b[A\n",
      "  1%|▌                                                                            | 88/12500 [01:59<4:06:57,  1.19s/it]\u001b[A\n",
      "  1%|▌                                                                            | 89/12500 [02:01<4:00:47,  1.16s/it]\u001b[A\n",
      "  1%|▌                                                                            | 90/12500 [02:02<3:58:28,  1.15s/it]\u001b[A\n",
      "  1%|▌                                                                            | 91/12500 [02:03<3:53:03,  1.13s/it]\u001b[A\n",
      "  1%|▌                                                                            | 92/12500 [02:04<3:52:00,  1.12s/it]\u001b[A\n",
      "  1%|▌                                                                            | 93/12500 [02:05<3:50:46,  1.12s/it]\u001b[A\n",
      "  1%|▌                                                                            | 94/12500 [02:06<3:45:50,  1.09s/it]\u001b[A\n",
      "  1%|▌                                                                            | 95/12500 [02:07<3:42:19,  1.08s/it]\u001b[A\n",
      "  1%|▌                                                                            | 96/12500 [02:08<3:41:28,  1.07s/it]\u001b[A\n",
      "  1%|▌                                                                            | 97/12500 [02:09<3:40:48,  1.07s/it]\u001b[A\n",
      "  1%|▌                                                                            | 98/12500 [02:10<3:38:26,  1.06s/it]\u001b[A\n",
      "  1%|▌                                                                            | 99/12500 [02:13<4:38:18,  1.35s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:13<02:13, 133.34s/it]\n",
      "  0%|                                                                                         | 0/1250 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0000e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                               | 1/1250 [00:05<1:57:10,  5.63s/it]\u001b[A\n",
      "  0%|▏                                                                              | 2/1250 [00:06<1:28:53,  4.27s/it]\u001b[A\n",
      "  0%|▏                                                                              | 3/1250 [00:08<1:10:06,  3.37s/it]\u001b[A\n",
      "  0%|▎                                                                                | 4/1250 [00:09<56:25,  2.72s/it]\u001b[A\n",
      "  0%|▎                                                                                | 5/1250 [00:10<46:31,  2.24s/it]\u001b[A\n",
      "  0%|▍                                                                                | 6/1250 [00:11<38:45,  1.87s/it]\u001b[A\n",
      "  1%|▍                                                                                | 7/1250 [00:12<33:17,  1.61s/it]\u001b[A\n",
      "  1%|▌                                                                                | 8/1250 [00:13<31:24,  1.52s/it]\u001b[A\n",
      "  1%|▌                                                                                | 9/1250 [00:14<28:11,  1.36s/it]\u001b[A\n",
      "  1%|▋                                                                               | 10/1250 [00:15<26:14,  1.27s/it]\u001b[A\n",
      "  1%|▋                                                                               | 11/1250 [00:16<24:42,  1.20s/it]\u001b[A\n",
      "  1%|▊                                                                               | 12/1250 [00:17<23:49,  1.15s/it]\u001b[A\n",
      "  1%|▊                                                                               | 13/1250 [00:18<22:48,  1.11s/it]\u001b[A\n",
      "  1%|▉                                                                               | 14/1250 [00:19<22:13,  1.08s/it]\u001b[A\n",
      "  1%|▉                                                                               | 15/1250 [00:20<22:27,  1.09s/it]\u001b[A\n",
      "  1%|█                                                                               | 16/1250 [00:22<24:17,  1.18s/it]\u001b[A\n",
      "  1%|█                                                                               | 17/1250 [00:23<24:04,  1.17s/it]\u001b[A\n",
      "  1%|█▏                                                                              | 18/1250 [00:24<24:21,  1.19s/it]\u001b[A\n",
      "  2%|█▏                                                                              | 19/1250 [00:25<25:01,  1.22s/it]\u001b[A\n",
      "  2%|█▎                                                                              | 20/1250 [00:27<24:49,  1.21s/it]\u001b[A\n",
      "  2%|█▎                                                                              | 21/1250 [00:28<25:05,  1.23s/it]\u001b[A\n",
      "  2%|█▍                                                                              | 22/1250 [00:29<23:54,  1.17s/it]\u001b[A\n",
      "  2%|█▍                                                                              | 23/1250 [00:30<22:44,  1.11s/it]\u001b[A\n",
      "  2%|█▌                                                                              | 24/1250 [00:31<22:38,  1.11s/it]\u001b[A\n",
      "  2%|█▌                                                                              | 25/1250 [00:32<23:28,  1.15s/it]\u001b[A\n",
      "  2%|█▋                                                                              | 26/1250 [00:33<23:50,  1.17s/it]\u001b[A\n",
      "  2%|█▋                                                                              | 27/1250 [00:35<23:48,  1.17s/it]\u001b[A\n",
      "  2%|█▊                                                                              | 28/1250 [00:36<25:11,  1.24s/it]\u001b[A\n",
      "  2%|█▊                                                                              | 29/1250 [00:37<25:11,  1.24s/it]\u001b[A\n",
      "  2%|█▉                                                                              | 30/1250 [00:38<24:23,  1.20s/it]\u001b[A\n",
      "  2%|█▉                                                                              | 31/1250 [00:40<24:17,  1.20s/it]\u001b[A\n",
      "  3%|██                                                                              | 32/1250 [00:41<25:50,  1.27s/it]\u001b[A\n",
      "  3%|██                                                                              | 33/1250 [00:42<24:53,  1.23s/it]\u001b[A\n",
      "  3%|██▏                                                                             | 34/1250 [00:43<24:08,  1.19s/it]\u001b[A\n",
      "  3%|██▏                                                                             | 35/1250 [00:45<25:04,  1.24s/it]\u001b[A\n",
      "  3%|██▎                                                                             | 36/1250 [00:46<26:19,  1.30s/it]\u001b[A\n",
      "  3%|██▎                                                                             | 37/1250 [00:47<26:44,  1.32s/it]\u001b[A\n",
      "  3%|██▍                                                                             | 38/1250 [00:49<25:19,  1.25s/it]\u001b[A\n",
      "  3%|██▍                                                                             | 39/1250 [00:50<25:25,  1.26s/it]\u001b[A\n",
      "  3%|██▌                                                                             | 40/1250 [00:51<25:08,  1.25s/it]\u001b[A\n",
      "  3%|██▌                                                                             | 41/1250 [00:52<26:18,  1.31s/it]\u001b[A\n",
      "  3%|██▋                                                                             | 42/1250 [00:54<26:22,  1.31s/it]\u001b[A\n",
      "  3%|██▊                                                                             | 43/1250 [00:55<26:26,  1.31s/it]\u001b[A\n",
      "  4%|██▊                                                                             | 44/1250 [00:56<24:34,  1.22s/it]\u001b[A\n",
      "  4%|██▉                                                                             | 45/1250 [00:57<24:20,  1.21s/it]\u001b[A\n",
      "  4%|██▉                                                                             | 46/1250 [00:58<24:06,  1.20s/it]\u001b[A\n",
      "  4%|███                                                                             | 47/1250 [01:00<24:11,  1.21s/it]\u001b[A\n",
      "  4%|███                                                                             | 48/1250 [01:01<24:43,  1.23s/it]\u001b[A\n",
      "  4%|███▏                                                                            | 49/1250 [01:02<25:00,  1.25s/it]\u001b[A\n",
      "  4%|███▏                                                                            | 50/1250 [01:04<25:25,  1.27s/it]\u001b[A\n",
      "  4%|███▎                                                                            | 51/1250 [01:05<25:26,  1.27s/it]\u001b[A\n",
      "  4%|███▎                                                                            | 52/1250 [01:06<25:37,  1.28s/it]\u001b[A\n",
      "  4%|███▍                                                                            | 53/1250 [01:07<25:38,  1.28s/it]\u001b[A\n",
      "  4%|███▍                                                                            | 54/1250 [01:09<26:24,  1.32s/it]\u001b[A\n",
      "  4%|███▌                                                                            | 55/1250 [01:10<25:56,  1.30s/it]\u001b[A\n",
      "  4%|███▌                                                                            | 56/1250 [01:12<26:30,  1.33s/it]\u001b[A\n",
      "  5%|███▋                                                                            | 57/1250 [01:13<25:32,  1.28s/it]\u001b[A\n",
      "  5%|███▋                                                                            | 58/1250 [01:14<25:36,  1.29s/it]\u001b[A\n",
      "  5%|███▊                                                                            | 59/1250 [01:15<25:49,  1.30s/it]\u001b[A\n",
      "  5%|███▊                                                                            | 60/1250 [01:17<25:48,  1.30s/it]\u001b[A\n",
      "  5%|███▉                                                                            | 61/1250 [01:18<25:08,  1.27s/it]\u001b[A\n",
      "  5%|███▉                                                                            | 62/1250 [01:19<24:19,  1.23s/it]\u001b[A\n",
      "  5%|████                                                                            | 63/1250 [01:20<23:24,  1.18s/it]\u001b[A\n",
      "  5%|████                                                                            | 64/1250 [01:21<22:33,  1.14s/it]\u001b[A\n",
      "  5%|████▏                                                                           | 65/1250 [01:22<21:44,  1.10s/it]\u001b[A\n",
      "  5%|████▏                                                                           | 66/1250 [01:23<21:52,  1.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                           | 67/1250 [01:24<21:29,  1.09s/it]\u001b[A\n",
      "  5%|████▎                                                                           | 68/1250 [01:25<21:00,  1.07s/it]\u001b[A\n",
      "  6%|████▍                                                                           | 69/1250 [01:26<20:44,  1.05s/it]\u001b[A\n",
      "  6%|████▍                                                                           | 70/1250 [01:27<21:18,  1.08s/it]\u001b[A\n",
      "  6%|████▌                                                                           | 71/1250 [01:29<21:20,  1.09s/it]\u001b[A\n",
      "  6%|████▌                                                                           | 72/1250 [01:30<20:58,  1.07s/it]\u001b[A\n",
      "  6%|████▋                                                                           | 73/1250 [01:31<20:37,  1.05s/it]\u001b[A\n",
      "  6%|████▋                                                                           | 74/1250 [01:32<20:39,  1.05s/it]\u001b[A\n",
      "  6%|████▊                                                                           | 75/1250 [01:33<20:58,  1.07s/it]\u001b[A\n",
      "  6%|████▊                                                                           | 76/1250 [01:34<20:52,  1.07s/it]\u001b[A\n",
      "  6%|████▉                                                                           | 77/1250 [01:35<20:49,  1.07s/it]\u001b[A\n",
      "  6%|████▉                                                                           | 78/1250 [01:36<20:47,  1.06s/it]\u001b[A\n",
      "  6%|█████                                                                           | 79/1250 [01:37<20:36,  1.06s/it]\u001b[A\n",
      "  6%|█████                                                                           | 80/1250 [01:38<20:22,  1.04s/it]\u001b[A\n",
      "  6%|█████▏                                                                          | 81/1250 [01:39<20:23,  1.05s/it]\u001b[A\n",
      "  7%|█████▏                                                                          | 82/1250 [01:40<21:47,  1.12s/it]\u001b[A\n",
      "  7%|█████▎                                                                          | 83/1250 [01:41<21:10,  1.09s/it]\u001b[A\n",
      "  7%|█████▍                                                                          | 84/1250 [01:43<21:41,  1.12s/it]\u001b[A\n",
      "  7%|█████▍                                                                          | 85/1250 [01:44<21:42,  1.12s/it]\u001b[A\n",
      "  7%|█████▌                                                                          | 86/1250 [01:45<22:10,  1.14s/it]\u001b[A\n",
      "  7%|█████▌                                                                          | 87/1250 [01:46<22:39,  1.17s/it]\u001b[A\n",
      "  7%|█████▋                                                                          | 88/1250 [01:47<22:52,  1.18s/it]\u001b[A\n",
      "  7%|█████▋                                                                          | 89/1250 [01:49<23:09,  1.20s/it]\u001b[A\n",
      "  7%|█████▊                                                                          | 90/1250 [01:50<23:50,  1.23s/it]\u001b[A\n",
      "  7%|█████▊                                                                          | 91/1250 [01:51<23:57,  1.24s/it]\u001b[A\n",
      "  7%|█████▉                                                                          | 92/1250 [01:52<22:37,  1.17s/it]\u001b[A\n",
      "  7%|█████▉                                                                          | 93/1250 [01:53<22:43,  1.18s/it]\u001b[A\n",
      "  8%|██████                                                                          | 94/1250 [01:54<22:21,  1.16s/it]\u001b[A\n",
      "  8%|██████                                                                          | 95/1250 [01:56<22:12,  1.15s/it]\u001b[A\n",
      "  8%|██████▏                                                                         | 96/1250 [01:57<23:14,  1.21s/it]\u001b[A\n",
      "  8%|██████▏                                                                         | 97/1250 [01:58<23:49,  1.24s/it]\u001b[A\n",
      "  8%|██████▎                                                                         | 98/1250 [02:00<24:03,  1.25s/it]\u001b[A\n",
      "  8%|██████▎                                                                         | 99/1250 [02:02<23:46,  1.24s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:16<00:00, 128.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_box_acc = predict(dataloaders_dict, scratch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7.0000e-05), tensor(0.)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_box_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain inception on transformed data and check accuracy on train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t AuxLogits.fc.weight\n",
      "\t AuxLogits.fc.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = []\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "##finetuned model accuracy\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
